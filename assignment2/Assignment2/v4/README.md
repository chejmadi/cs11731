This directory consists of the concat, then segment model, but for a consistent segmentation. In fact, to do so, I'm gonna start the experiment entirely from scratch, just with the corpus bolstered by the synthetic data. I will train a new subword model and a new en-{af,ts,nso} model. In v3, I'm segmenting first then concatenating (but keeping the same subword model throughout), so I'm going to continue training from the baseline. 
